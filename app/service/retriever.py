import re
import os
import json
import weaviate.classes as wvc
import google.generativeai as genai
from dotenv import load_dotenv
from typing import List, Dict, Any, Union
from app.schemas import SearchQuery
from app.core.config import GOOGLE_API_KEY
from app.core.database import supabase, weaviate_client

load_dotenv()

raw_env = os.getenv("RELATIONS_MAP", "{}")

RELATIONS_MAP = json.loads(raw_env)

async def fetch_vector_candidates(db_type: str, vector: List[float], params: SearchQuery, limit: int) -> List[Dict[str, Any]]:
    """
    ì§€ì •ëœ DBì—ì„œ ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ í›„ë³´êµ°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    if db_type.lower() == "supabase":
        response = supabase.rpc('match_documents', {
            'query_embedding': vector,
            'match_threshold': 0.2,
            'match_count': limit,
            'filter': params.filter
        }).execute()
        return response.data
    
    # 2. Weaviate ë¡œì§ ì¶”ê°€
    elif db_type == "weaviate":
        collection_name = "Welfare_Doc" 
        collection = weaviate_client.collections.get(collection_name)
        
        # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
        result = collection.query.near_vector(
            near_vector=vector,
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(distance=True)
        )
        
        # Supabaseì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¡œ ë°ì´í„° ë³€í™˜
        # similarityëŠ” (1 - distance)ë¡œ ê³„ì‚°í•˜ì—¬ 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.
        formatted_results = []
        for obj in result.objects:
            formatted_results.append({
                "content": obj.properties.get("content", ""),
                "metadata": obj.properties.get("metadata", {}),
                "similarity": 1 - (obj.metadata.distance if obj.metadata.distance is not None else 0)
            })
        return formatted_results
    
    return []

def get_ngrams(text: str) -> set:
    # JS: text.replace(/[^\wã„±-ã…ê°€-í£]/g, '')
    # Python: ì˜ë¬¸(a-z), ìˆ«ì(0-9), ë°‘ì¤„(_), í•œê¸€(ã„±-ã…, ê°€-í£)ì„ ì œì™¸í•˜ê³  ëª¨ë‘ ì œê±°
    clean_text = re.sub(r'[^a-zA-Z0-9_ã„±-ã…ê°€-í£]', '', text)
    
    grams = set()
    # 2ê¸€ìì”© ìë¥´ê¸°
    for i in range(len(clean_text) - 1):
        grams.add(clean_text[i:i+2])
    return grams

def embedding_query(params: SearchQuery) -> List[float]:
    if GOOGLE_API_KEY:
        genai.configure(api_key=GOOGLE_API_KEY)
        
    embedding_result = genai.embed_content(
        model="models/gemini-embedding-001",
        content=params.query_text,
        task_type="retrieval_query"
    )

    return embedding_result['embedding']


async def search_logic(params: SearchQuery, db_type: str = "supabase") -> List[Dict[str, Any]]:
    
    vector = embedding_query(params)

    CANDIDATE_LIMIT = 200
    
    raw_results = await fetch_vector_candidates(db_type, vector, params, CANDIDATE_LIMIT)

    if not raw_results:
        return []

    query_text = params.query_text
    
    # í‚¤ì›Œë“œ (2ê¸€ì ì´ìƒ, ê³µë°± ê¸°ì¤€ ë¶„ë¦¬)
    query_keywords = [w for w in query_text.split() if len(w) >= 2]
    
    # 2-gram (í•¨ìˆ˜ ì‚¬ìš©)
    query_grams = get_ngrams(query_text)

    # ìµœì¢… ì»·íŠ¸ë¼ì¸
    FINAL_THRESHOLD = 0.6
    ranked_results = []

    # ì •ë°€ ì±„ì 
    for doc in raw_results:
        content = doc.get('content', '') or ""
        
        # ê¸°ë³¸ ì ìˆ˜ (ë²¡í„° ìœ ì‚¬ë„)
        # JSì˜ cosineSimilarity(queryVector, docVector)ì™€ ë™ì¼
        score = doc.get('similarity', 0)
        
        # [ë¡œì§ A] í‚¤ì›Œë“œ ë§¤ì¹­ (+0.1)
        # JS: queryKeywords.forEach(word => { if (content.includes(word)) score += 0.1; });
        for word in query_keywords:
            if word in content:
                score += 0.1
        
        # [ë¡œì§ B] 2-gram ë§¤ì¹­ (+0.02)
        # JS: queryGrams.forEach(gram => { if (content.includes(gram)) gramMatchCount++; });
        gram_match_count = 0
        for gram in query_grams:
            if gram in content:
                gram_match_count += 1
        
        score += (gram_match_count * 0.02)

        # ìµœì¢… í•„í„°ë§
        if score > FINAL_THRESHOLD:
            doc['final_score'] = score
            ranked_results.append(doc)

    # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬ (JS: b.score - a.score)
    ranked_results.sort(key=lambda x: x['final_score'], reverse=True)

    # ê°œìˆ˜ ì œí•œ (JS: getCount)
    return ranked_results[:params.return_count]


async def search_target_table(params: SearchQuery) -> List[Dict[str, Any]]:
    # 1. ì‚¬ìš©ì ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜ (Gemini ì„ë² ë”©)
    vector = embedding_query(params)
    
    # 2. ê²€ìƒ‰í•  8ê°œ í…Œì´ë¸” ëª©ë¡
    target_collections = [
        "Welfare_Doc", "Receipt", "Company", "Ceo_message", 
        "General", "Resource", "Mutual_aid", "Etc"
    ]
    
    limit_per_table = 3
    
    # ğŸ’¡ [ë³€ê²½ í¬ì¸íŠ¸] ì „ì²´ë¥¼ í•©ì¹˜ì§€ ì•Šê³ , í…Œì´ë¸”ë³„ë¡œ ê²°ê³¼ë¥¼ ë³´ê´€í•  ë”•ì…”ë„ˆë¦¬ ì¤€ë¹„
    table_results = {}
    table_max_scores = {}

    # 3. ê° í…Œì´ë¸”ì„ ëŒë©´ì„œ ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
    for collection_name in target_collections:
        try:
            collection = weaviate_client.collections.get(collection_name)
            
            result = collection.query.near_vector(
                near_vector=vector,
                limit=limit_per_table,
                return_metadata=wvc.query.MetadataQuery(distance=True)
            )
            
            candidates = []
            max_similarity = 0 # ì´ í…Œì´ë¸”ì˜ 1ë“± ì ìˆ˜
            
            # 4. ë°ì´í„° ë³€í™˜ ë° ì´ í…Œì´ë¸”ì˜ 'ìµœê³  ìœ ì‚¬ë„' ì°¾ê¸°
            for obj in result.objects:
                distance = obj.metadata.distance if obj.metadata.distance is not None else 0
                similarity = 1 - distance
                
                candidates.append({
                    "id": str(obj.uuid),
                    "collection": collection_name, # ğŸ’¡ ë‚˜ì¤‘ì— ì¶œì²˜ë¥¼ ë°íˆê¸° ìœ„í•´ í…Œì´ë¸”ëª… ê¸°ë¡
                    "content": obj.properties.get("content", ""),
                    "fileName": obj.properties.get("fileName", ""), # íŒŒì¼ëª…ë„ ê¼­ ê°€ì ¸ì˜¤ì„¸ìš”
                    "similarity": similarity
                })
                
                # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ ê°±ì‹ 
                if similarity > max_similarity:
                    max_similarity = similarity
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ 1ê°œë¼ë„ ìˆë‹¤ë©´ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥
            if candidates:
                table_results[collection_name] = candidates
                table_max_scores[collection_name] = max_similarity

        except Exception as e:
            # íŠ¹ì • í…Œì´ë¸”ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ë©ˆì¶”ì§€ ì•Šê³  íŒ¨ìŠ¤
            print(f"âš ï¸ [Weaviate] {collection_name} í…Œì´ë¸” ì¡°íšŒ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
            continue

    # 5. [í•µì‹¬ ë¡œì§] ê°€ì¥ ë†’ì€ ìµœê³  ì ìˆ˜ë¥¼ ì œì¶œí•œ í…Œì´ë¸” ì°¾ê¸°
    if not table_max_scores:
        print("âš ï¸ ëª¨ë“  í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    best_table = max(table_max_scores, key=table_max_scores.get)
    best_score = table_max_scores[best_table]

    print(f"âœ… [SEARCH DONE] 1ë“± í…Œì´ë¸” ì„ ì •: {best_table} (ìµœê³  ìœ ì‚¬ë„: {best_score:.4f})")
    
    # 6. ë‹¤ë¥¸ í…Œì´ë¸” ê²°ê³¼ëŠ” ì „ë¶€ ë¬´ì‹œí•˜ê³ , 1ë“± í…Œì´ë¸”ì˜ ë°ì´í„°ë§Œ ê°€ì ¸ì˜´
    best_candidates = table_results[best_table]
    
    # í™•ì‹¤í•˜ê²Œ ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ í•œ ë²ˆ ë” ì •ë ¬
    best_candidates.sort(key=lambda x: x["similarity"], reverse=True)
    
    # 7. ì„¤ì •ëœ match_count(ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 3)ë§Œí¼ ì˜ë¼ì„œ ìµœì¢… ë¦¬í„´
    final_count = params.match_count if hasattr(params, 'match_count') else 3
    top_results = best_candidates[:final_count]
    
    return top_results

async def fetch_data_by_ids(table_name: str, ids: Union[str, List[str]]) -> List[Dict[str, Any]]:
    """
    1ì°¨ ê²€ìƒ‰ì—ì„œ ì°¾ì€ IDsë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ ë°ì´í„°ì™€ 'ì—°ê²°ëœ ê´€ê³„ë„ ë°ì´í„°'ë¥¼ í•œ ë²ˆì— ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    # ë‹¨ì¼ ID(ë¬¸ìì—´)ê°€ ë“¤ì–´ì™€ë„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
    if isinstance(ids, str):
        ids = [ids]
        
    try:
        collection = weaviate_client.collections.get(table_name)
        
        # 1. ì´ í…Œì´ë¸”ì— ì„¤ì •ëœ ê´€ê³„ë„(Edge) ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        edge_name = RELATIONS_MAP.get(table_name)
        
        # 2. ê´€ê³„ë„ê°€ ì¡´ì¬í•œë‹¤ë©´, ë¶€ëª¨/ìì‹ ë°ì´í„°ë„ ê°™ì´ ê°€ì ¸ì˜¤ë„ë¡ ì„¸íŒ… (í•µì‹¬ ğŸ’¡)
        return_references = []
        
        wq = wvc.query
        
        if edge_name:
            return_references.append(
                wq.QueryReference(
                    link_on=edge_name,
                    return_properties=["content", "fileName"] # ì—°ê²°ëœ ë¬¸ì„œì˜ ë‚´ìš©ê³¼ íŒŒì¼ëª…
                )
            )
        
        # 3. ID ë°°ì—´ë¡œ ë°ì´í„° ì¡°íšŒ (GraphQLì˜ ContainsAny ì—­í• )
        result = collection.query.fetch_objects(
            filters=wq.Filter.by_id().contains_any(ids),
            return_references=return_references if return_references else None
        )
        
        final_results = []
        
        # 4. Agentê°€ ì½ê¸° ì¢‹ê²Œ ì›ë³¸ ë‚´ìš©ê³¼ ê´€ê³„ë„ ë‚´ìš©ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
        for obj in result.objects:
            main_content = obj.properties.get("content", "")
            file_name = obj.properties.get("fileName", "")
            
            cross_ref_content = ""
            
            # ì—°ê²°ëœ ë°ì´í„°ê°€ ìˆë‹¤ë©´ í…ìŠ¤íŠ¸ë¡œ í’€ì–´ì£¼ê¸°
            if edge_name and obj.references and edge_name in obj.references:
                for ref_obj in obj.references[edge_name].objects:
                    ref_text = ref_obj.properties.get("content", "")
                    ref_file = ref_obj.properties.get("fileName", "")
                    cross_ref_content += f"\n[ì°¸ì¡° ë¬¸ì„œ: {ref_file}] {ref_text}"
            
            final_results.append({
                "id": str(obj.uuid),
                "table": table_name,
                "fileName": file_name,
                "content": main_content,
                "cross_reference": cross_ref_content.strip() # AI íŒë‹¨ì„ ë•ëŠ” ë’·ë°°ê²½ ì§€ì‹
            })
            
        return final_results
        
    except Exception as e:
        print(f"âš ï¸ [{table_name}] ID ê¸°ë°˜ ë°ì´í„° ì¡°íšŒ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return []